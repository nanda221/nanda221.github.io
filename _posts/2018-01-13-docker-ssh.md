---
layout: post
title:  "Docker——容器的远程连接"
subtitle: "Access Docker Container By SSH Remotely"
date:   2017-01-13 23:59:59 +0800
background: '/img/posts/06.jpg'
---

## 问题：工作中的远程连接

远程连接，这是一种习惯。

在笔者的工作环境，无论应用是否Docker化，从运维的角度讲，都不建议(甚至是禁止)直接远程登录服务器进行日志查询、甚至是重启等操作，取而代之的是各产品化的解决方案：比如B/S形态更产品化的日志查询、应用生命周期管理等等。

但程序员对“掌控感”的渴求与生俱来，运行环境上下文中有什么、发生了什么、结果是什么，这些问题一定要到“现场”才最痛快直接。所以在测试环境等一切允许的场景，都是“登”上去一顿操作。

## Docker环境下的一些变化

对于开发人员，大家更多关注了它在DevOps方面的优势，但另一方面，得益于操作系统级的虚拟化和LXC技术，它让应用的粒度可以更小、启动更快、伸缩更容易。问题也随之出现，和数量更多的Docker容器点对点的建立远程连接，是否现实。

从理念来看，业界也存在争论。Docker的理念是一个容器只运行一个服务，如果需要远程连接，每个容器运行一个额外的SSH守护进程服务，有违这一理念。

回到本文，这里不打算探讨实际生产中的连接问题，而是重点阐述在本地开发中不可避免的容器连接和管理问题。

## 本地容器化管理之前

设想一下，在Docker之前，我们是如何在本地写代码、做研发甚至是学技术的：了解自己的系统(Mac或是其他)；通过brew/yum/apt-get安装系统工具包、安装技术栈运行环境，还有数据库、IDE及其他编程辅助程序、版本控制软件、工程化套件。。。直到新的需求出现，前面的程序将周而复始。慢慢地，你将拥有一台很“强大”的电脑，用起来非常趁手，编写的程序都可以完美运行，简直无所不能。但有两个问题需要思考。

### 交付——换台机器，我写的代码还能跑吗？

举个例子，在本地的Mac系统进行开发，使用了NodeJS Latest版本，完成了一个webapp。然后我把代码部署到测试环境——一个装有NodeJS LTS版本的CentOS系统。这里至少已经出现了两个明显的风险点，1.不同系统的NodeJS安装；2.LTS环境无法实用Latest的某些新特性。一句话：我们交付的只是代码，而不是一个对代码+环境的完整描述。可以通过增加运行环境说明(readme)来一定程度解决这个问题，但这并不可靠和优雅。

### 混乱——多版本、多技术栈

举个例子，使用jekyll搭建个人博客，需要Ruby运行环境(2.5)。Mac自带Ruby运行环境，但版本较低。对系统版本进行升级不可取(系统程序依赖低版本)，只能使用RVM做多版本管理。当我们需要用最新的Python版本完成一个爬虫程序时，同样的事情发生在Python(系统2.7)和Python3。多个技术栈和多版本(或是版本管理工具)，让本地这个“应用”非常臃肿和混乱，一段时间以后很难记得哪些技术组合解决哪些开发问题。

## 本地容器化管理之后

与其说引入Docker，不如说是引入了一种思想。围绕一件尽量内聚的事情，将运行环境和代码“封装”在一个环境里，以服务的形式对外透出。熟悉面向对象思想和编程原则的朋友一定觉得非常熟悉，只是原则的范围扩大到了整个运行环境，甚至是操作系统。Docker帮我们做好了准备工作。




















